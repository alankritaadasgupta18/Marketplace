{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaae691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/23/2024 09:22:13 AM \u001b[92m Obtained utoken email from file \u001b[0m\n",
      "12/23/2024 09:22:14 AM \u001b[92m Obtained utoken from utoken cli \u001b[0m\n",
      "12/23/2024 09:22:14 AM \u001b[92m Obtained utoken email from file \u001b[0m\n",
      "12/23/2024 09:22:15 AM \u001b[92m Obtained utoken from utoken cli \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from querybuilder_client import QuerybuilderClient\n",
    "from queryrunner_client import Client\n",
    "import datetime\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "import pygsheets\n",
    "import ast\n",
    "import IPython\n",
    "from numpy import nan\n",
    "import json\n",
    "# import pypostmaster\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import os\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "qr = Client(user_email='mrajor@ext.uber.com', consumer_name='marketplace-mobility-ops-analytics')\n",
    "\n",
    "gc = pygsheets.authorize(service_file='meehir.json')\n",
    "\n",
    "wsaccess = pygsheets.authorize(service_file='meehir.json')\n",
    "main_sheet = wsaccess.open_by_key('1lBKqpEENuGZAPXsLgEr9OWoqe8MniU4bjolehpwBwl8')\n",
    "details = main_sheet.worksheet_by_title('manually_handled_npi')\n",
    "qr = Client(user_email='mrajor@ext.uber.com', consumer_name='marketplace-mobility-ops-analytics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc31d3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report</th>\n",
       "      <th>tab_name</th>\n",
       "      <th>sheet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zgirSXWh5</td>\n",
       "      <td>Uber_raw_data</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1lBKqpE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qFbg9Uofx</td>\n",
       "      <td>ola_raw_data</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1lBKqpE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Report       tab_name                                              sheet\n",
       "0  zgirSXWh5  Uber_raw_data  https://docs.google.com/spreadsheets/d/1lBKqpE...\n",
       "1  qFbg9Uofx   ola_raw_data  https://docs.google.com/spreadsheets/d/1lBKqpE..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet=details.get_as_df()\n",
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ff1fc7-8a3d-4d33-8289-c209904cebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.google.com/spreadsheets/d/1lBKqpEENuGZAPXsLgEr9OWoqe8MniU4bjolehpwBwl8/edit?gid=1719304691#gid=1719304691\n",
      "https://docs.google.com/spreadsheets/d/1lBKqpEENuGZAPXsLgEr9OWoqe8MniU4bjolehpwBwl8/edit?gid=0#gid=0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    print(sheet.iloc[i,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8eb969f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22\n",
      "2024-12-23\n"
     ]
    }
   ],
   "source": [
    "today=datetime.today()\n",
    "start_date=today-timedelta(days=1)\n",
    "end_date=today-timedelta(days=0)\n",
    "start=start_date.strftime(\"%Y-%m-%d\")\n",
    "end=end_date.strftime(\"%Y-%m-%d\")\n",
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a6c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "week_number=start_date.isocalendar()[1]\n",
    "print(week_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb96eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_in_wks_replace(dash_link,tab_name,df):\n",
    "    wks=gc.open_by_url(dash_link).worksheet_by_title(tab_name)\n",
    "    wks.clear()\n",
    "    lastrow=len(wks.get_col(1,include_tailing_empty=False)) + 1\n",
    "    wks.set_dataframe(df,start='A{}'.format(lastrow),copy_head=False)\n",
    "    print(\"data uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0231003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_in_wks(dash_link,tab_name,df):\n",
    "    wks=gc.open_by_url(dash_link).worksheet_by_title(tab_name)\n",
    "    wks.add_rows(df.shape[0])\n",
    "    lastrow=len(wks.get_col(1,include_tailing_empty=False)) + 1\n",
    "    wks.set_dataframe(df,start='A{}'.format(lastrow),copy_head=False)\n",
    "    print(\"data uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37caf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_types_common(df):\n",
    "    df['day'] = df['day'].astype(str)\n",
    "    df['Time'] = df['Time'].astype(str)\n",
    "    df['city_name'] = df['city_name'].astype(str)\n",
    "    df['scr_geo'] = df['scr_geo'].astype(str)\n",
    "    df['dest_geo'] = df['dest_geo'].astype(str)\n",
    "    df['Distance_bucket'] = df['Distance_bucket'].astype(str)\n",
    "#     df['week'] = df['week'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eacf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_df(uber_df, df):\n",
    "    print(\"Uber DataFrame Columns:\", uber_df.columns.tolist())\n",
    "    print(\"Input DataFrame Columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Ensure 'day' is in datetime format\n",
    "    df['day'] = pd.to_datetime(df['day'])\n",
    "    df['day'] = df['day'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Ensure numeric types for relevant columns, check if they exist\n",
    "    numeric_columns = ['sum_fare', 'sum_dist', 'points', 'requests', 'req weighted dist']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        if col in uber_df.columns:\n",
    "            uber_df[col] = pd.to_numeric(uber_df[col], errors='coerce')\n",
    "\n",
    "    # Merge DataFrames\n",
    "    merged_df = pd.merge(uber_df, df, on=['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'], how='inner')\n",
    "\n",
    "    # Group and transform\n",
    "    if 'sum_fare' in merged_df.columns:\n",
    "        merged_df['sum_fare'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['sum_fare'].transform('sum')\n",
    "    if 'sum_dist' in merged_df.columns:\n",
    "        merged_df['sum_dist'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['sum_dist'].transform('sum')\n",
    "    if 'points' in merged_df.columns:\n",
    "        merged_df['points'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['points'].transform('sum')\n",
    "\n",
    "    merged_df['day'] = pd.to_datetime(merged_df['day'])\n",
    "    merged_df['week'] = merged_df['day'].dt.isocalendar().week\n",
    "\n",
    "    if 'requests' in merged_df.columns:\n",
    "        merged_df['requests'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['requests'].transform('sum')\n",
    "    if 'req weighted dist' in merged_df.columns:\n",
    "        merged_df['uber_dist'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['req weighted dist'].transform('sum')\n",
    "\n",
    "    # Convert requests to int\n",
    "    if 'requests' in merged_df.columns:\n",
    "        merged_df['requests'] = merged_df['requests'].astype(int)\n",
    "\n",
    "    # Calculate weighted fare only if columns exist\n",
    "    if 'sum_fare' in merged_df.columns and 'sum_dist' in merged_df.columns and 'uber_dist' in merged_df.columns:\n",
    "        merged_df['req weighted fare'] = (merged_df['sum_fare'] / merged_df['sum_dist']) * merged_df['uber_dist']\n",
    "    if 'requests' in merged_df.columns and 'sum_dist' in merged_df.columns:\n",
    "        merged_df['req weighted dist'] = merged_df['requests'] * merged_df['sum_dist']\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed6cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_df_rapido(uber_df, df):\n",
    "    print(\"Rapido Uber DataFrame Columns:\", uber_df.columns.tolist())\n",
    "    print(\"Input DataFrame Columns:\", df.columns.tolist())\n",
    "    \n",
    "    df['day'] = pd.to_datetime(df['day'])\n",
    "    df['day'] = df['day'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Ensure numeric types for relevant columns, check if they exist\n",
    "    numeric_columns = ['sum_fare_pre', 'sum_fare_post', 'sum_dist', 'points', 'requests', 'req weighted dist']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        if col in uber_df.columns:\n",
    "            uber_df[col] = pd.to_numeric(uber_df[col], errors='coerce')\n",
    "\n",
    "    merged_df = pd.merge(uber_df, df, on=['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'], how='inner')\n",
    "\n",
    "    if 'sum_fare_pre' in merged_df.columns:\n",
    "        merged_df['sum_fare_pre'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['sum_fare_pre'].transform('sum')\n",
    "    if 'sum_fare_post' in merged_df.columns:\n",
    "        merged_df['sum_fare_post'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['sum_fare_post'].transform('sum')\n",
    "    if 'sum_dist' in merged_df.columns:\n",
    "        merged_df['sum_dist'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['sum_dist'].transform('sum')\n",
    "    if 'points' in merged_df.columns:\n",
    "        merged_df['points'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['points'].transform('sum')\n",
    "\n",
    "    #merged_df['week'] = merged_df['day'].dt.isocalendar().week\n",
    "    merged_df['week'] = week_number\n",
    "\n",
    "    if 'requests' in merged_df.columns:\n",
    "        merged_df['requests'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['requests'].transform('sum')\n",
    "    if 'req weighted dist' in merged_df.columns:\n",
    "        merged_df['uber_dist'] = merged_df.groupby(['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket'])['req weighted dist'].transform('sum')\n",
    "\n",
    "    if 'requests' in merged_df.columns:\n",
    "        merged_df['requests'] = merged_df['requests'].astype(int)\n",
    "\n",
    "    if 'sum_fare_pre' in merged_df.columns and 'sum_dist' in merged_df.columns and 'uber_dist' in merged_df.columns:\n",
    "        merged_df['req weighted fare_pre'] = (merged_df['sum_fare_pre'] / merged_df['sum_dist']) * merged_df['uber_dist']\n",
    "    if 'sum_fare_post' in merged_df.columns and 'sum_dist' in merged_df.columns and 'uber_dist' in merged_df.columns:\n",
    "        merged_df['req weighted fare_post'] = (merged_df['sum_fare_post'] / merged_df['sum_dist']) * merged_df['uber_dist']\n",
    "    \n",
    "    if 'requests' in merged_df.columns and 'sum_dist' in merged_df.columns:\n",
    "        merged_df['req weighted dist'] = merged_df['requests'] * merged_df['sum_dist']\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9071151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/22/2024 07:00:33 AM \u001b[93m Could not obtain utoken from cli: b'/bin/sh: 1: usso: not found\\n'\n",
      "Trying to obtain from file \u001b[0m\n",
      "12/22/2024 07:00:33 AM \u001b[92m Obtained utoken for user \u001b[0m\n",
      "12/22/2024 07:00:33 AM \u001b[93m Fetching metadata for Report zgirSXWh5 \u001b[0m\n",
      "12/22/2024 07:00:33 AM \u001b[92m Loaded object metadata. \u001b[0m\n",
      "12/22/2024 07:00:33 AM \u001b[93m Templating query for report zgirSXWh5 \u001b[0m\n",
      "12/22/2024 07:00:33 AM \u001b[92m Templated query successfully. \u001b[0m\n",
      "12/22/2024 07:00:33 AM Send tier_metadata {'report_id': 'zgirSXWh5'} to Queryrunner V2.\n",
      "12/22/2024 07:00:33 AM \u001b[93m [Polling] c007cf47-4cf1-41c9-9097-43be1d65adeb \u001b[0m\n",
      "12/22/2024 07:00:33 AM \u001b[93m [Status] created \u001b[0m\n",
      "12/22/2024 07:00:34 AM \u001b[93m [Status] started validation \u001b[0m\n",
      "12/22/2024 07:00:38 AM \u001b[93m [Status] started auth check \u001b[0m\n",
      "12/22/2024 07:00:42 AM \u001b[93m [Status] started waiting to execute \u001b[0m\n",
      "12/22/2024 07:02:18 AM \u001b[93m [Status] started execution \u001b[0m\n",
      "12/22/2024 07:04:44 AM \u001b[93m UToken has expired. Generating new utoken. \u001b[0m\n",
      "12/22/2024 07:04:44 AM \u001b[92m Obtained utoken email from file \u001b[0m\n",
      "12/22/2024 07:04:44 AM \u001b[92m Obtained utoken from utoken cli \u001b[0m\n",
      "12/22/2024 07:08:24 AM \u001b[93m [Status] completed success \u001b[0m\n",
      "12/22/2024 07:08:24 AM \u001b[92m [Query Success] completed success \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[93m Could not obtain utoken from cli: b'/bin/sh: 1: usso: not found\\n'\n",
      "Trying to obtain from file \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[92m Obtained utoken for user \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[93m Fetching metadata for Report qFbg9Uofx \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[92m Loaded object metadata. \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[93m Templating query for report qFbg9Uofx \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[92m Templated query successfully. \u001b[0m\n",
      "12/22/2024 07:08:47 AM Send tier_metadata {'report_id': 'qFbg9Uofx'} to Queryrunner V2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data uploaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/22/2024 07:08:47 AM \u001b[93m [Polling] 472e87d7-3f8e-40c1-bce8-74983e2d09e4 \u001b[0m\n",
      "12/22/2024 07:08:47 AM \u001b[93m [Status] created \u001b[0m\n",
      "12/22/2024 07:08:48 AM \u001b[93m [Status] started validation \u001b[0m\n",
      "12/22/2024 07:08:49 AM \u001b[93m [Status] started auth check \u001b[0m\n",
      "12/22/2024 07:08:50 AM \u001b[93m [Status] started waiting to execute \u001b[0m\n",
      "12/22/2024 07:08:51 AM \u001b[93m [Status] started execution \u001b[0m\n",
      "12/22/2024 07:09:07 AM \u001b[93m [Status] completed success \u001b[0m\n",
      "12/22/2024 07:09:07 AM \u001b[92m [Query Success] completed success \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            day                  Time   city_name        scr_geo  \\\n",
      "0    2024-12-20    Evening_peak_17_20      Mumbai           city   \n",
      "1    2024-12-20  Afternoon_hour_11_16      Mumbai           city   \n",
      "2    2024-12-20    Evening_peak_17_20   Delhi NCR  Uttar Pradesh   \n",
      "3    2024-12-20     Morning_peak_7_10   Delhi NCR          Delhi   \n",
      "4    2024-12-20     Morning_peak_7_10      Mumbai           city   \n",
      "...         ...                   ...         ...            ...   \n",
      "4902 2024-12-20           Night_21_23     Lucknow        airport   \n",
      "4903 2024-12-20        Graveyard_0_06   Ahmedabad           city   \n",
      "4904 2024-12-20    Evening_peak_17_20  Chandigarh           city   \n",
      "4905 2024-12-20        Graveyard_0_06   Delhi NCR          Delhi   \n",
      "4906 2024-12-20        Graveyard_0_06       Kochi        airport   \n",
      "\n",
      "           dest_geo Distance_bucket      sum_fare      sum_dist points  \\\n",
      "0              city          50 km+  4.409719e+07  1.999686e+06  25015   \n",
      "1           airport        16-18 km  3.355313e+06  1.285840e+05   6023   \n",
      "2     Uttar Pradesh          2-4 km  8.430245e+06  1.834599e+05  57332   \n",
      "3             Delhi         8-10 km  1.757662e+07  8.542758e+05  89077   \n",
      "4           airport          6-8 km  1.737411e+06  4.662049e+04   6032   \n",
      "...             ...             ...           ...           ...    ...   \n",
      "4902        airport          4-6 km  1.867070e+03  6.034510e+01     14   \n",
      "4903        airport        35-40 km  4.499300e+02  3.616827e+01      1   \n",
      "4904           city        45-50 km  4.059680e+03  2.919026e+02      6   \n",
      "4905           city        12-14 km  3.215860e+03  1.297593e+02     10   \n",
      "4906           city        18-20 km  2.333440e+03  1.145005e+02      6   \n",
      "\n",
      "     requests  week  req weighted fare  req weighted dist  \n",
      "0        1586    51       4.409719e+07       1.999686e+06  \n",
      "1         820    51       3.355313e+06       1.285840e+05  \n",
      "2        4190    51       8.430245e+06       1.834599e+05  \n",
      "3        8206    51       1.757662e+07       8.542758e+05  \n",
      "4         677    51       1.737411e+06       4.662049e+04  \n",
      "...       ...   ...                ...                ...  \n",
      "4902        2    51       1.867070e+03       6.034510e+01  \n",
      "4903        1    51       4.499300e+02       3.616827e+01  \n",
      "4904        1    51       4.059680e+03       2.919026e+02  \n",
      "4905        0    51       3.215860e+03       1.297593e+02  \n",
      "4906        1    51       2.333440e+03       1.145005e+02  \n",
      "\n",
      "[4907 rows x 13 columns]\n",
      "Uber DataFrame Columns: ['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket', 'requests', 'req weighted dist']\n",
      "Input DataFrame Columns: ['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket', 'sum_fare', 'sum_dist', 'points']\n",
      "data uploaded\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_307618/3191092009.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmoto_uber_df_web\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmoto_uber_df_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatacenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'phx2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Uber_raw_data'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dsw/snapshots/1b75112a-85fa-4b13-9c56-5822402b8861/python310/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dsw/snapshots/1b75112a-85fa-4b13-9c56-5822402b8861/python310/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3909\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mCaller\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mresponsible\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchecking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3910\u001b[0m         \"\"\"\n\u001b[1;32m   3911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3912\u001b[0m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3913\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3915\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# Main Logic\n",
    "ola_uber_df = pd.DataFrame()\n",
    "app_df = pd.DataFrame()\n",
    "rapido_uber_df = pd.DataFrame()\n",
    "moto_uber_df_web = pd.DataFrame()\n",
    "moto_uber_df_app = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 2):\n",
    "    df = qr.execute_report(sheet.iloc[i, 0], parameters={\"start\": start, \"end\": end}, datacenter='phx2').to_pandas()\n",
    "    \n",
    "    if sheet.iloc[i, 1] == 'Uber_raw_data':\n",
    "        df['day'] = pd.to_datetime(df['day'])\n",
    "        df['week'] = df['day'].dt.isocalendar().week\n",
    "        df['req weighted fare'] = df['sum_fare']\n",
    "        df['req weighted dist'] = df['sum_dist']\n",
    "        ola_uber_df = df\n",
    "        rapido_uber_df = df\n",
    "        app_df = df\n",
    "        upload_in_wks(sheet.iloc[i, 2], sheet.iloc[i, 1], df) \n",
    "        \n",
    "    elif sheet.iloc[i, 1] == 'ola_raw_data':\n",
    "        print(app_df)\n",
    "        app_df.drop(columns=['sum_fare', 'sum_dist', 'points', 'req weighted fare', 'week'], inplace=True)\n",
    "        app_df = make_data_types_common(app_df)\n",
    "        df = make_data_types_common(df)\n",
    "        new_df = merging_df(app_df, df)\n",
    "        temp_df = new_df[['day', 'Time', 'city_name', 'scr_geo', 'dest_geo', 'Distance_bucket',\n",
    "                           'sum_fare', 'sum_dist', 'points', 'week', 'requests',\n",
    "                           'req weighted fare', 'uber_dist', 'req weighted dist']]\n",
    "        upload_in_wks(sheet.iloc[i, 2], sheet.iloc[i, 1], temp_df)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc39d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Python 3.10 (General DS)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
